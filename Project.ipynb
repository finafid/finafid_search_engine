{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id              Category          Title  \\\n",
      "0   1  HOME &amp; LIFESTYLE      GEO TOKYO   \n",
      "1   2  HOME &amp; LIFESTYLE      GEO TOKYO   \n",
      "2   3  HOME &amp; LIFESTYLE      WEST PORT   \n",
      "3   4  HOME &amp; LIFESTYLE  PACIFIC COAST   \n",
      "4   5  HOME &amp; LIFESTYLE       ENVOUGUE   \n",
      "\n",
      "                               Description  \n",
      "0             DOUBLE BED SHEET FOREST BLUE  \n",
      "1       DOUBLE BED SHEET FOREST GOLD/MULTI  \n",
      "2               DOUBLE BED SHEET TURQUIOSE  \n",
      "3  PACIFIC COAST DOUBLE BED SHEET TURQUISE  \n",
      "4      ENVOGUE DOUBLE BEDSHEET IVORY/MULTI  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "amazon_df = pd.read_csv('amazon_product.csv')\n",
    "\n",
    "# Display the first 5 rows of the DataFrame\n",
    "print(amazon_df.head(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_df.drop('id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sr.No</th>\n",
       "      <th>Category</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>HOME &amp;amp; LIFESTYLE</td>\n",
       "      <td>GEO TOKYO</td>\n",
       "      <td>DOUBLE BED SHEET FOREST BLUE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>HOME &amp;amp; LIFESTYLE</td>\n",
       "      <td>GEO TOKYO</td>\n",
       "      <td>DOUBLE BED SHEET FOREST GOLD/MULTI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>HOME &amp;amp; LIFESTYLE</td>\n",
       "      <td>WEST PORT</td>\n",
       "      <td>DOUBLE BED SHEET TURQUIOSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>HOME &amp;amp; LIFESTYLE</td>\n",
       "      <td>PACIFIC COAST</td>\n",
       "      <td>PACIFIC COAST DOUBLE BED SHEET TURQUISE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>HOME &amp;amp; LIFESTYLE</td>\n",
       "      <td>ENVOUGUE</td>\n",
       "      <td>ENVOGUE DOUBLE BEDSHEET IVORY/MULTI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sr.No              Category          Title  \\\n",
       "0      1  HOME &amp; LIFESTYLE      GEO TOKYO   \n",
       "1      2  HOME &amp; LIFESTYLE      GEO TOKYO   \n",
       "2      3  HOME &amp; LIFESTYLE      WEST PORT   \n",
       "3      4  HOME &amp; LIFESTYLE  PACIFIC COAST   \n",
       "4      5  HOME &amp; LIFESTYLE       ENVOUGUE   \n",
       "\n",
       "                               Description  Unnamed: 4  Unnamed: 5  \\\n",
       "0             DOUBLE BED SHEET FOREST BLUE         NaN         NaN   \n",
       "1       DOUBLE BED SHEET FOREST GOLD/MULTI         NaN         NaN   \n",
       "2               DOUBLE BED SHEET TURQUIOSE         NaN         NaN   \n",
       "3  PACIFIC COAST DOUBLE BED SHEET TURQUISE         NaN         NaN   \n",
       "4      ENVOGUE DOUBLE BEDSHEET IVORY/MULTI         NaN         NaN   \n",
       "\n",
       "   Unnamed: 6  Unnamed: 7  Unnamed: 8  Unnamed: 9  \n",
       "0         NaN         NaN         NaN         NaN  \n",
       "1         NaN         NaN         NaN         NaN  \n",
       "2         NaN         NaN         NaN         NaN  \n",
       "3         NaN         NaN         NaN         NaN  \n",
       "4         NaN         NaN         NaN         NaN  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONVERT TEXT TO LOWERCASE AND UPPER CASE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title          0\n",
       "Description    0\n",
       "Category       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUNCTION FOR TOKENIZATION AND STREAMING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ANKITA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['how', 'are', 'you', 'brother', '?', 'i', 'am', 'good.what', 'about', 'you', '?']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ANKITA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')  # Ensure that 'punkt' is downloaded\n",
    "\n",
    "tokens = nltk.word_tokenize('how are you brother? i am good.what about you?')\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ANKITA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "# Ensure that 'punkt' is downloaded for tokenization\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Initialize the stemmer\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "def tokenize_stem(text):\n",
    "    # Tokenize the text\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    stemmed = [stemmer.stem(w) for w in tokens]\n",
    "    return \" \".join(stemmed)\n",
    "\n",
    "    # Stem each token\n",
    "    #stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    #return stemmed_tokens\n",
    "\n",
    "# Example usage\n",
    "#text = 'how are you brother'\n",
    "#stemmed_tokens = tokenize_stem(text)\n",
    "#print(stemmed_tokens)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Category          Title  \\\n",
      "0    HOME &amp; LIFESTYLE      GEO TOKYO   \n",
      "1    HOME &amp; LIFESTYLE      GEO TOKYO   \n",
      "2    HOME &amp; LIFESTYLE      WEST PORT   \n",
      "3    HOME &amp; LIFESTYLE  PACIFIC COAST   \n",
      "4    HOME &amp; LIFESTYLE       ENVOUGUE   \n",
      "..                    ...            ...   \n",
      "193             HAIR CARE    SCHWARZKOPF   \n",
      "194             HAIR CARE    SCHWARZKOPF   \n",
      "195             HAIR CARE    SCHWARZKOPF   \n",
      "196  HOME &amp; LIFESTYLE        ThredCo   \n",
      "197  HOME &amp; LIFESTYLE        ThredCo   \n",
      "\n",
      "                                 Description  \\\n",
      "0               DOUBLE BED SHEET FOREST BLUE   \n",
      "1         DOUBLE BED SHEET FOREST GOLD/MULTI   \n",
      "2                 DOUBLE BED SHEET TURQUIOSE   \n",
      "3    PACIFIC COAST DOUBLE BED SHEET TURQUISE   \n",
      "4        ENVOGUE DOUBLE BEDSHEET IVORY/MULTI   \n",
      "..                                       ...   \n",
      "193                     Anti Dendraf Shampoo   \n",
      "194           REPAIR RESCUE SHAMPOO ARGININE   \n",
      "195                       FRIZZ AWAY SHAMPOO   \n",
      "196                       Round Neck T Shirt   \n",
      "197                             Polo T Shirt   \n",
      "\n",
      "                                      stemmed_tokens  \n",
      "0              geo tokyo doubl bed sheet forest blue  \n",
      "1        geo tokyo doubl bed sheet forest gold/multi  \n",
      "2                 west port doubl bed sheet turquios  \n",
      "3    pacif coast pacif coast doubl bed sheet turquis  \n",
      "4          envougu envogu doubl bedsheet ivory/multi  \n",
      "..                                               ...  \n",
      "193                 schwarzkopf anti dendraf shampoo  \n",
      "194         schwarzkopf repair rescu shampoo arginin  \n",
      "195                   schwarzkopf frizz away shampoo  \n",
      "196                       thredco round neck t shirt  \n",
      "197                             thredco polo t shirt  \n",
      "\n",
      "[198 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have a DataFrame 'amazon_df' with columns 'Title' and 'Description'\n",
    "\n",
    "'''import pandas as pd'''\n",
    "\n",
    "# Example DataFrame\n",
    "'''data = {\n",
    "    'Title': ['Product 1', 'Product 2'],\n",
    "    'Description': ['This is the first product.', 'This is the second product.']\n",
    "}\n",
    "amazon_df = pd.DataFrame(data)'''\n",
    "\n",
    "# Applying the tokenize_stem function to each row\n",
    "amazon_df['stemmed_tokens'] = amazon_df.apply(lambda row: tokenize_stem(row['Title'] + \" \" + row['Description']), axis=1)\n",
    "\n",
    "print(amazon_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Category</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>HOME &amp;amp; LIFESTYLE</td>\n",
       "      <td>GEO TOKYO</td>\n",
       "      <td>DOUBLE BED SHEET FOREST BLUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>HOME &amp;amp; LIFESTYLE</td>\n",
       "      <td>GEO TOKYO</td>\n",
       "      <td>DOUBLE BED SHEET FOREST GOLD/MULTI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>HOME &amp;amp; LIFESTYLE</td>\n",
       "      <td>WEST PORT</td>\n",
       "      <td>DOUBLE BED SHEET TURQUIOSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>HOME &amp;amp; LIFESTYLE</td>\n",
       "      <td>PACIFIC COAST</td>\n",
       "      <td>PACIFIC COAST DOUBLE BED SHEET TURQUISE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>HOME &amp;amp; LIFESTYLE</td>\n",
       "      <td>ENVOUGUE</td>\n",
       "      <td>ENVOGUE DOUBLE BEDSHEET IVORY/MULTI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>HOME &amp;amp; LIFESTYLE</td>\n",
       "      <td>ENVOUGUE</td>\n",
       "      <td>ENVOGUE DOUBLE BEDSHEET SAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>HOME &amp;amp; LIFESTYLE</td>\n",
       "      <td>GEO TOKYO</td>\n",
       "      <td>GEO TOKYO DOUBLE BED SHEET BLUE/SAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>HOME &amp;amp; LIFESTYLE</td>\n",
       "      <td>GEO TOKYO</td>\n",
       "      <td>GEO TOKYO DOUBLE BEDSHEET GREY/DK.GREY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>HOME &amp;amp; LIFESTYLE</td>\n",
       "      <td>COASTRAL STRIPE</td>\n",
       "      <td>COASTAL STRIPE DOUBLE BEDSHEET CORAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>HOME &amp;amp; LIFESTYLE</td>\n",
       "      <td>COASTRAL STRIPE</td>\n",
       "      <td>COASTAL STRIPE DOUBLE BEDSHEET TAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>HOME &amp;amp; LIFESTYLE</td>\n",
       "      <td>COASTRAL STRIPE</td>\n",
       "      <td>COASTAL STRIPE DOUBLE BEDSHEET SAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>HOME &amp;amp; LIFESTYLE</td>\n",
       "      <td>COASTRAL STRIPE</td>\n",
       "      <td>COASTAL STRIPE DOUBLE BEDSHEET GREY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>HOME &amp;amp; LIFESTYLE</td>\n",
       "      <td>COASTRAL STRIPE</td>\n",
       "      <td>COASTRAL STRIPE DOUBLE BEDSHEET WHITE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>HOME &amp;amp; LIFESTYLE</td>\n",
       "      <td>ENVOUGUE</td>\n",
       "      <td>ENVOGUE DOUBLE BEDSHEET CORAL/MULTI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>HOME &amp;amp; LIFESTYLE</td>\n",
       "      <td>PACIFIC COAST</td>\n",
       "      <td>PACIFIC COAST DOUBLE BEDSHEET BLUE/MULTI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id              Category            Title  \\\n",
       "0    1  HOME &amp; LIFESTYLE        GEO TOKYO   \n",
       "1    2  HOME &amp; LIFESTYLE        GEO TOKYO   \n",
       "2    3  HOME &amp; LIFESTYLE        WEST PORT   \n",
       "3    4  HOME &amp; LIFESTYLE    PACIFIC COAST   \n",
       "4    5  HOME &amp; LIFESTYLE         ENVOUGUE   \n",
       "5    6  HOME &amp; LIFESTYLE         ENVOUGUE   \n",
       "6    7  HOME &amp; LIFESTYLE        GEO TOKYO   \n",
       "7    8  HOME &amp; LIFESTYLE        GEO TOKYO   \n",
       "8    9  HOME &amp; LIFESTYLE  COASTRAL STRIPE   \n",
       "9   10  HOME &amp; LIFESTYLE  COASTRAL STRIPE   \n",
       "10  11  HOME &amp; LIFESTYLE  COASTRAL STRIPE   \n",
       "11  12  HOME &amp; LIFESTYLE  COASTRAL STRIPE   \n",
       "12  13  HOME &amp; LIFESTYLE  COASTRAL STRIPE   \n",
       "13  14  HOME &amp; LIFESTYLE         ENVOUGUE   \n",
       "14  15  HOME &amp; LIFESTYLE    PACIFIC COAST   \n",
       "\n",
       "                                 Description  \n",
       "0               DOUBLE BED SHEET FOREST BLUE  \n",
       "1         DOUBLE BED SHEET FOREST GOLD/MULTI  \n",
       "2                 DOUBLE BED SHEET TURQUIOSE  \n",
       "3    PACIFIC COAST DOUBLE BED SHEET TURQUISE  \n",
       "4        ENVOGUE DOUBLE BEDSHEET IVORY/MULTI  \n",
       "5               ENVOGUE DOUBLE BEDSHEET SAGE  \n",
       "6       GEO TOKYO DOUBLE BED SHEET BLUE/SAGE  \n",
       "7     GEO TOKYO DOUBLE BEDSHEET GREY/DK.GREY  \n",
       "8       COASTAL STRIPE DOUBLE BEDSHEET CORAL  \n",
       "9         COASTAL STRIPE DOUBLE BEDSHEET TAN  \n",
       "10       COASTAL STRIPE DOUBLE BEDSHEET SAND  \n",
       "11       COASTAL STRIPE DOUBLE BEDSHEET GREY  \n",
       "12     COASTRAL STRIPE DOUBLE BEDSHEET WHITE  \n",
       "13       ENVOGUE DOUBLE BEDSHEET CORAL/MULTI  \n",
       "14  PACIFIC COAST DOUBLE BEDSHEET BLUE/MULTI  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "tfidfv = TfidfVectorizer(tokenizer=tokenize_stem)\n",
    "\n",
    "def cosine_sim(txt1,txt2):\n",
    "    matrix = tfidfv.fit_transform([txt1,txt2])\n",
    "    return cosine_similarity(matrix)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def search_product(query, amazon_df):\n",
    "    # Calculate stemmed query\n",
    "    stemmed_query = tokenize_stem(query)\n",
    "    \n",
    "    # Calculate cosine similarity between query and stemmed tokens columns\n",
    "    amazon_df['similarity'] = amazon_df['stemmed_tokens'].apply(lambda x: cosine_sim(stemmed_query, x))\n",
    "    \n",
    "    # Sort by 'similarity' in descending order and select top 10 results\n",
    "    res = amazon_df.sort_values(by='similarity', ascending=False).head(10)[['Title', 'Description', 'Category']]\n",
    "    \n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Title                            Description  \\\n",
      "9   COASTRAL STRIPE     COASTAL STRIPE DOUBLE BEDSHEET TAN   \n",
      "8   COASTRAL STRIPE   COASTAL STRIPE DOUBLE BEDSHEET CORAL   \n",
      "10  COASTRAL STRIPE    COASTAL STRIPE DOUBLE BEDSHEET SAND   \n",
      "11  COASTRAL STRIPE    COASTAL STRIPE DOUBLE BEDSHEET GREY   \n",
      "12  COASTRAL STRIPE  COASTRAL STRIPE DOUBLE BEDSHEET WHITE   \n",
      "5          ENVOUGUE           ENVOGUE DOUBLE BEDSHEET SAGE   \n",
      "29         ENVOUGUE          ENVOGUE DOUBLE BEDSHEET BEIGH   \n",
      "28         ENVOUGUE           ENVOGUE DOUBLE BEDSHEET AQUA   \n",
      "22          HAMPTON         HAMPTON DOUBLE BEDSHEET BRONZE   \n",
      "26          HAMPTON       HAMPTON DOUBLE BEDSHEET RED/NAVY   \n",
      "\n",
      "                Category  \n",
      "9   HOME &amp; LIFESTYLE  \n",
      "8   HOME &amp; LIFESTYLE  \n",
      "10  HOME &amp; LIFESTYLE  \n",
      "11  HOME &amp; LIFESTYLE  \n",
      "12  HOME &amp; LIFESTYLE  \n",
      "5   HOME &amp; LIFESTYLE  \n",
      "29  HOME &amp; LIFESTYLE  \n",
      "28  HOME &amp; LIFESTYLE  \n",
      "22  HOME &amp; LIFESTYLE  \n",
      "26  HOME &amp; LIFESTYLE  \n"
     ]
    }
   ],
   "source": [
    "'''import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Ensure you have downloaded the necessary NLTK data files\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Example preprocess function\n",
    "def preprocess(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    return ' '.join(stemmed_tokens)\n",
    "\n",
    "# Load your data\n",
    "amazon_df = pd.read_csv('amazon_product.csv')\n",
    "\n",
    "# Ensure the 'Description' column exists and preprocess it\n",
    "if 'Description' in amazon_df.columns:\n",
    "    amazon_df['stemmed_tokens'] = amazon_df['Description'].apply(preprocess)\n",
    "else:\n",
    "    print(\"Error: 'Description' column not found in the DataFrame.\")\n",
    "\n",
    "# Now define your search_product function\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def cosine_sim(query, document):\n",
    "    vectorizer = CountVectorizer().fit_transform([query, document])\n",
    "    vectors = vectorizer.toarray()\n",
    "    return cosine_similarity(vectors)[0, 1]\n",
    "\n",
    "def search_product(query, amazon_df):\n",
    "    query = preprocess(query)  # Preprocess the query\n",
    "    amazon_df['similarity'] = amazon_df['stemmed_tokens'].apply(lambda x: cosine_sim(query, x))\n",
    "    res = amazon_df.sort_values(by='similarity', ascending=False).head(3)[['Title', 'Description', 'Category']]\n",
    "    return res'''\n",
    "\n",
    "# Example usage\n",
    "result = search_product('COASTAL STRIPE DOUBLE BEDSHEET TAN', amazon_df)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ENVOUGUE'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_df['Title'][4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
